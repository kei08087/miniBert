SST: can change batch size, learning rate, epochs, hdp
CFIMDB: can change learning rate, epochs, hdp

default: batch size 8 hdp 0.3 lr pre 1e-3 fine 1e-5 epoch 10


Accuracy in 3 epoch 8batch hdp 0.1 pre
SST: 0.305
CFIMDB: 0.482

Acc in 20 epoch 16 batch hdp 0.01 pre

CFIMDB: 0.490

New code

Acc in 2 epoch 32 batch hdp 0.01 pre

SST: 0.302
CFIMDB: 0.510

Acc in 1 epoch 256 batch pre

SST: 0.148
CFIMDB: 0.535

Acc in 1 epoch 2 batch pre

SST: 0.274
CFIMDB: 0.486

Acc in 5 epoch 64 batch hdp 0.4 pre

SST: 0.299
CFIMDB: 0.514

Acc in 20 epoch 64 batch hdp 0.2 pre lr 1e-4

SST: 0.357
CFIMDB 0.588

Acc in 10 epoch 64 batch hdp 0.2 pre

SST: 0.299
CFIMDB 0.596

Seems like lr and batch is critical to SST and hdp is critical to CFIMDB. But lr does not effect a lot in CFIMDB and hdp dos not on SST. Batch on CFIMDB is unable to define because it is blocked to change them.

Using the distance method for sts with batchsize 64 and dropout prob 0.15 cross entropy
save the model to pretrain-10-1e-05-multitask.pt
Epoch: 0 Train Accuracy: 0.185 Dev Accuracy 0.205
save the model to pretrain-10-1e-05-multitask.pt
Epoch: 1 Train Accuracy: 0.228 Dev Accuracy 0.257
save the model to pretrain-10-1e-05-multitask.pt
Epoch: 2 Train Accuracy: 0.262 Dev Accuracy 0.269
save the model to pretrain-10-1e-05-multitask.pt
Epoch: 3 Train Accuracy: 0.262 Dev Accuracy 0.272
Epoch: 4 Train Accuracy: 0.262 Dev Accuracy 0.272
Epoch: 5 Train Accuracy: 0.262 Dev Accuracy 0.272
Epoch: 6 Train Accuracy: 0.262 Dev Accuracy 0.272
Epoch: 7 Train Accuracy: 0.262 Dev Accuracy 0.272
Epoch: 8 Train Accuracy: 0.262 Dev Accuracy 0.272
Epoch: 9 Train Accuracy: 0.262 Dev Accuracy 0.272

sts distance method multiple negatives batchsize 64 dropout prob 0.15
Epoch: 0 Train Accuracy: 0.186 Dev Accuracy 0.212
Epoch: 1 Train Accuracy: 0.186 Dev Accuracy 0.212
Epoch: 2 Train Accuracy: 0.186 Dev Accuracy 0.212


